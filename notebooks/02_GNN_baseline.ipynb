{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-07T13:01:15.340306Z",
     "start_time": "2025-09-07T13:01:08.624577Z"
    }
   },
   "source": [
    "# In[1]: Cell 1 - 필요한 모듈 및 경로 설정\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# WorkFrame 폴더의 경로를 추가하여 스텝별 스크립트를 import 할 수 있도록 함\n",
    "# 이 노트북 파일이 'root/notebooks/'에 있다고 가정\n",
    "workframe_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'WorkFrame'))\n",
    "if workframe_path not in sys.path:\n",
    "    sys.path.append(workframe_path)\n",
    "\n",
    "import run_step5_prepare_gnn_data as step5\n",
    "import run_step6_train_gnn_model as step6"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\pyspace\\envs\\polygnn\\Lib\\site-packages\\torch_geometric\\typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: [WinError 127] 지정된 프로시저를 찾을 수 없습니다\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "E:\\pyspace\\envs\\polygnn\\Lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] 지정된 프로시저를 찾을 수 없습니다\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "E:\\pyspace\\envs\\polygnn\\Lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] 지정된 프로시저를 찾을 수 없습니다\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "E:\\pyspace\\envs\\polygnn\\Lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] 지정된 프로시저를 찾을 수 없습니다\n",
      "  warnings.warn(\n",
      "E:\\pyspace\\envs\\polygnn\\Lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] 지정된 프로시저를 찾을 수 없습니다\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T13:02:53.793653Z",
     "start_time": "2025-09-07T13:02:37.192739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# In[2]: Cell 2 - 5단계 실행: GNN 데이터셋 준비\n",
    "# imputed_final_data.csv 파일을 읽어 GNN이 사용할 수 있는 그래프 데이터셋으로 변환하고 저장합니다.\n",
    "# 이 셀은 한 번만 실행하면 됩니다.\n",
    "step5.main()"
   ],
   "id": "cca37b4b3704ed72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5단계 시작: GNN 데이터셋 준비 ---\n",
      "대상 물성: ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
      "SMILES를 그래프 데이터로 변환 중... (시간이 걸릴 수 있습니다)\n",
      "그래프 변환 완료. 총 10343개의 유효한 분자 데이터 생성.\n",
      "\n",
      "--- 5단계 완료 ---\n",
      "처리된 데이터셋이 'E:/SSL-polyGNN/data/processed/gnn_dataset.pt'에 저장되었습니다.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T13:43:57.253247Z",
     "start_time": "2025-09-07T13:03:28.899452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# In[3]: Cell 3 - 6단계 실행: GNN 모델 학습\n",
    "# 위에서 생성한 데이터셋을 불러와 K-fold 교차 검증으로 모델을 학습합니다.\n",
    "# 학습 과정(Epoch별 Loss)이 이 셀의 출력 창에 표시됩니다.\n",
    "# 학습이 완료되면 최종 성능과 함께 모델 파일이 'root/model/' 폴더에 저장됩니다.\n",
    "step6.main()"
   ],
   "id": "b4e6821c7ff13b29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6단계 시작: GNN 모델 학습 ---\n",
      "사용 장치: cuda\n",
      "\n",
      "===== Fold 1/5 =====\n",
      "Epoch 001 | Train Loss: 2430.7221 | Val Loss: 1217.2559\n",
      "Epoch 010 | Train Loss: 972.9030 | Val Loss: 786.5198\n",
      "Epoch 020 | Train Loss: 906.1099 | Val Loss: 714.5302\n",
      "Epoch 030 | Train Loss: 866.0552 | Val Loss: 685.7071\n",
      "Epoch 040 | Train Loss: 812.4205 | Val Loss: 656.8478\n",
      "Epoch 050 | Train Loss: 798.6108 | Val Loss: 652.9719\n",
      "Epoch 060 | Train Loss: 776.2268 | Val Loss: 690.1607\n",
      "Epoch 070 | Train Loss: 760.3277 | Val Loss: 609.2947\n",
      "Epoch 080 | Train Loss: 741.0899 | Val Loss: 594.0068\n",
      "Epoch 090 | Train Loss: 750.9163 | Val Loss: 606.0130\n",
      "Epoch 100 | Train Loss: 727.1239 | Val Loss: 574.3458\n",
      "Fold 1 최적 Val Loss: 573.4292\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "Epoch 001 | Train Loss: 2429.3624 | Val Loss: 1321.4793\n",
      "Epoch 010 | Train Loss: 1020.8406 | Val Loss: 866.0327\n",
      "Epoch 020 | Train Loss: 947.6723 | Val Loss: 679.1697\n",
      "Epoch 030 | Train Loss: 872.3544 | Val Loss: 676.3289\n",
      "Epoch 040 | Train Loss: 842.8516 | Val Loss: 687.0255\n",
      "Epoch 050 | Train Loss: 820.6881 | Val Loss: 619.3565\n",
      "Epoch 060 | Train Loss: 791.0401 | Val Loss: 590.6459\n",
      "Epoch 070 | Train Loss: 778.1514 | Val Loss: 641.9569\n",
      "Epoch 080 | Train Loss: 767.1188 | Val Loss: 567.6318\n",
      "Epoch 090 | Train Loss: 769.9168 | Val Loss: 560.6390\n",
      "Epoch 100 | Train Loss: 755.4696 | Val Loss: 581.8781\n",
      "Fold 2 최적 Val Loss: 558.9666\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "Epoch 001 | Train Loss: 2345.1212 | Val Loss: 1073.3123\n",
      "Epoch 010 | Train Loss: 1011.3439 | Val Loss: 798.2542\n",
      "Epoch 020 | Train Loss: 898.0718 | Val Loss: 691.8176\n",
      "Epoch 030 | Train Loss: 889.3942 | Val Loss: 711.1180\n",
      "Epoch 040 | Train Loss: 827.8062 | Val Loss: 651.2851\n",
      "Epoch 050 | Train Loss: 830.4036 | Val Loss: 607.8961\n",
      "Epoch 060 | Train Loss: 786.8210 | Val Loss: 619.7318\n",
      "Epoch 070 | Train Loss: 779.1778 | Val Loss: 577.9314\n",
      "Epoch 080 | Train Loss: 762.6261 | Val Loss: 574.9223\n",
      "Epoch 090 | Train Loss: 759.2862 | Val Loss: 561.0898\n",
      "Epoch 100 | Train Loss: 764.0285 | Val Loss: 621.1198\n",
      "Fold 3 최적 Val Loss: 560.8367\n",
      "\n",
      "===== Fold 4/5 =====\n",
      "Epoch 001 | Train Loss: 2464.6222 | Val Loss: 1193.0242\n",
      "Epoch 010 | Train Loss: 992.5659 | Val Loss: 803.5511\n",
      "Epoch 020 | Train Loss: 910.3318 | Val Loss: 714.7223\n",
      "Epoch 030 | Train Loss: 845.4173 | Val Loss: 667.9074\n",
      "Epoch 040 | Train Loss: 819.0512 | Val Loss: 713.7782\n",
      "Epoch 050 | Train Loss: 804.6762 | Val Loss: 628.7871\n",
      "Epoch 060 | Train Loss: 786.3260 | Val Loss: 619.0844\n",
      "Epoch 070 | Train Loss: 779.1329 | Val Loss: 606.0522\n",
      "Epoch 080 | Train Loss: 746.0546 | Val Loss: 709.7017\n",
      "Epoch 090 | Train Loss: 742.4810 | Val Loss: 607.0182\n",
      "Epoch 100 | Train Loss: 718.5894 | Val Loss: 611.7136\n",
      "Fold 4 최적 Val Loss: 579.6042\n",
      "\n",
      "===== Fold 5/5 =====\n",
      "Epoch 001 | Train Loss: 2344.0724 | Val Loss: 1218.2163\n",
      "Epoch 010 | Train Loss: 933.8039 | Val Loss: 818.2885\n",
      "Epoch 020 | Train Loss: 827.3604 | Val Loss: 707.5785\n",
      "Epoch 030 | Train Loss: 810.4577 | Val Loss: 738.1710\n",
      "Epoch 040 | Train Loss: 786.9163 | Val Loss: 675.9372\n",
      "Epoch 050 | Train Loss: 771.9661 | Val Loss: 630.4320\n",
      "Epoch 060 | Train Loss: 753.0398 | Val Loss: 650.0784\n",
      "Epoch 070 | Train Loss: 738.4397 | Val Loss: 653.8877\n",
      "Epoch 080 | Train Loss: 730.1742 | Val Loss: 623.7568\n",
      "Epoch 090 | Train Loss: 715.4326 | Val Loss: 593.1729\n",
      "Epoch 100 | Train Loss: 721.8437 | Val Loss: 597.3622\n",
      "Fold 5 최적 Val Loss: 590.6289\n",
      "\n",
      "--- 6단계 완료 ---\n",
      "K-Fold 교차 검증 결과 (MSE Loss):\n",
      "  평균: 572.6931\n",
      "  표준편차: 11.8236\n",
      "최적 모델들이 'model/' 디렉토리에 저장되었습니다.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# In[4]: Cell 4 - (선택 사항) 학습된 모델로 예측해보기\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# myutility 폴더 경로 추가\n",
    "myutility_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'myutility'))\n",
    "if myutility_path not in sys.path:\n",
    "    sys.path.append(myutility_path)\n",
    "\n",
    "import gnn_utils as gu\n",
    "\n",
    "# --- 설정 ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 5가지 물성 예측\n",
    "NUM_TARGETS = 5\n",
    "# 1번 Fold에서 가장 성능이 좋았던 모델을 불러옵니다.\n",
    "MODEL_PATH = '../model/best_model_fold_1.pth'\n",
    "# 테스트해볼 SMILES\n",
    "TEST_SMILES = \"CCO\" # Ethanol\n",
    "\n",
    "# --- 모델 로드 ---\n",
    "model = gu.GCNNet(in_channels=36, hidden_channels=128, out_channels=NUM_TARGETS)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# --- 예측 ---\n",
    "# 예측을 위해서는 y값이 필요 없으므로 임의의 값을 넣어줌\n",
    "graph_data = gu.smiles_to_graph(TEST_SMILES, torch.zeros(NUM_TARGETS)).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(graph_data)\n",
    "\n",
    "print(f\"SMILES '{TEST_SMILES}'의 예측 물성값:\")\n",
    "# 원본 데이터의 물성 순서대로 출력 (예시)\n",
    "properties = ['Density', 'FFV', 'Rg', 'Tc', 'Tg']\n",
    "for name, val in zip(properties, prediction.squeeze().cpu().numpy()):\n",
    "    print(f\"  - {name}: {val:.4f}\")"
   ],
   "id": "85aa0e15707b2f07"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
